\documentclass[mathserif]{beamer}%
%
\xdef\sharedDir{../_shared_}%
\RequirePackage{\sharedDir/styles/slides}%
%
\subtitle{6. Evolutionary Algorithms}%
%
\begin{document}%
\startPresentation%
%
\section{Introduction}%
%
\begin{frame}%
\frametitle{Introduction}%
\begin{itemize}%
\item Hill Climbers are local search.%
\item<2-> They begin at some point~$\sespel$ in the search space and then investigate its neighborhood~$N(\sespel)$.%
\item<3-> The neighborhood is defined by the (unary) search operator, in our case \algoStyle{1swap} or \algoStyle{nswap}.%
\item<4-> If they reach a local optimum~$\localOptimum{\sespel}$, they get trapped.%
\item<5-> We then can restart them, but this means\uncover<5->{
\begin{enumerate}%
\item to start again back at ``zero'' and losing all accumulated information\uncover<6->{ and}%
\item<6-> they may still land again in a local optimum.%
\end{enumerate}%
}%
\item<7-> We can use unary operators which sample non-uniformly from larger neighborhoods, like \algoStyle{nswap}, but the search move needed to escape from a good but non-optimal point might be too unlikely.%
\item<8-> Idea: We could investigate multiple points in the search space at once and use the additional information in a clever way?%
\end{itemize}%
\end{frame}%
%
%
\begin{frame}%
\frametitle{Population-Based Metaheuristics}%
\begin{itemize}%
\item Population-based metaheuristics\cite{WGOEB,H1975GA,BFM1997EA,MF2004HTSIMH,G1989GA} try to maintain a \alert{set} of points in the search space which are iteratively refined.%%
\item<2-> This has a couple of advantages\uncover<3->{:%
\begin{itemize}%
\item We are less likely to get trapped in a single local optimum (because we work on multiple points).%
\item<4-> We might more likely find a better (local) optimum.%
\item<5-> If we have different good points from the search space in our population, we can try to use this additional information\dots%
\end{itemize}%
}%
\end{itemize}%
\end{frame}%
%
\section{Algorithm Concept: Population}%
%
\begin{frame}%
\frametitle{\texorpdfstring{$(\mu+\lambda)$}{(mu+lambda)}~EA}%
\begin{itemize}%
\item Evolutionary Algorithms (EAs) are the most successful family of population-based metaheuristics.\cite{WGOEB,BFM1997EA,MF2004HTSIMH}%
\item<2-> Here we focus on $(\mu+\lambda)$~EAs\uncover<3->{, which work as follows:%
\begin{enumerate}%
\item Generate a population of $\mu+\lambda$ random points in the search space (and map them to solutions and evaluate them).%
\item<4-> From the population, select the $\mu$~best points as ``parents'' for the next ``generation'' of points, discard the remaining $\lambda$~points.%
\item<5-> Generate $\lambda$~new ``offspring'' points by applying a unary search operator (which creates a randomly modified copy from a selected point).%
\item<6-> Evaluate the $\lambda$~offsprings, add them to the population, and go back to step~\enumerateItem{2}.%
\end{enumerate}%
}%
\end{itemize}%
\end{frame}%
%
\begin{frame}%
\frametitle{Ingredient: Individual Record}%
\listing{0.9}{0.9}{language=myJava,mathescape=false}{code/Individual.java}
\end{frame}%
%
\begin{frame}%
\frametitle{Evolutionary Algorithm Implementation}%
\only<1>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_01.java}}%
\only<2>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_02.java}}%
\only<3>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_03.java}}%
\only<4>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_04.java}}%
\only<5>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_05.java}}%
\only<6>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_06.java}}%
\only<7>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_07.java}}%
\only<8>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_08.java}}%
\only<9>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_09.java}}%
\only<10>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_10.java}}%
\only<11>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_11.java}}%
\only<12>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_12.java}}%
\only<13>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_13.java}}%
\only<14>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_14.java}}%
\only<15>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_15.java}}%
\only<16>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_16.java}}%
\only<17>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_17.java}}%
\only<18>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_18.java}}%
\only<19>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_19.java}}%
\only<20>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_20.java}}%
\only<21>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_21.java}}%
\only<22>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR_22.java}}%
\only<23>{\listing{0.9}{1.4}{language=myJava,mathescape=false}{code/EAnoCR.java}}%
\end{frame}%
%

\section{Configuring the Algorithm}%
%
\begin{frame}%
\frametitle{Algorithm Parameters}%
\only<-5,7->{%
\begin{itemize}%
\item Our EA has two parameters, $\mu$ and $\lambda$.%
\item<2-> Actually, it has three parameters\only<-2>{.}\uncover<3->{: We can choose \algoStyle{1swap} or \algoStyle{nswap} as unary search operation.}%
\item<4-> For now, let's set $\mu=\lambda$, meaning the number of parents equals the number of offspring in each generation.%
\item<5-> This leaves us two parameters to investigate, so let's take a look.%
\item<7-> Except for \instStyle{swv15}, a setting of $\mu=\lambda=16'384$ seems reasonable.%
\item<8-> Interestingly, there are only little differences between \algoStyle{1swap} and \algoStyle{nswap}\only<-8>{.}\uncover<9->{, but we pick \algoStyle{nswap} because it tends to be the better choice more often.}%
\item<10-> Generally, the EA seems to be quite robust and performs well for many parameter settings (except on \instStyle{swv15}).%
\end{itemize}%
}%
%
\locateGraphic{6}{width=0.95\paperwidth}{graphics/ea_nocr_config/ea_nocr_med_over_mu}{0.025}{0.13}%
%
\end{frame}%
%
\section{Experiment and Analysis}%
%
\begin{frame}[t]%
\frametitle{So what do we get?}%
%
 \only<3->{%
\begin{center}%
\only<3,5,7,9>{\small{\algoStyle{hcr_65536_nswap}: median result of 3~min of the restarted hill climber \algoStyle{hcr_65536_nswap} with $L=65'536$ and \algoStyle{nswap}}}%
\only<4,6,8,10>{\small{\algoStyle{ea_16384_nswap}: median result of 3~min of the EA with $\mu=\lambda=16'384$ with \algoStyle{nswap}}}%
\end{center}%
}%
%
\only<-2>{%
\begin{itemize}%
\item I execute the program 101~times for each of the instances \instStyle{abz7}, \instStyle{la24}, \instStyle{swv15}, and \instStyle{yn4}%
\end{itemize}%
\uncover<2->{%
\begin{center}%
\resizebox{0.9\linewidth}{!}{%
\begin{tabular}{|l|l|r|r|r|r|r|r|}%
\hline%
&&\multicolumn{4}{c|}{\textbf{makespan}}&\multicolumn{2}{c|}{\textbf{last improvement}}\\%
\hline%
$\instance$&algo&best&mean&med&sd&med(t)&med(FEs)\\%
\hline%
\hline%
\instStyle{abz7}&\algoStyle{hcr_65536_nswap}&712&731&732&\textcolor{green}{\textbf{6}}&96s&21'189'358\\%
&\algoStyle{ea_16384_nswap}&\textcolor{green}{\textbf{691}}&\textcolor{green}{\textbf{707}}&\textcolor{green}{\textbf{707}}&8&151s&25'293'859\\%
\hline%
\instStyle{la24}&\algoStyle{hcr_65536_nswap}&\textcolor{green}{\textbf{942}}&973&974&\textcolor{green}{\textbf{8}}&71s&31'466'420\\%
&\algoStyle{ea_16384_nswap}&945&\textcolor{green}{\textbf{968}}&\textcolor{green}{\textbf{967}}&12&39s&10'161'119\\%
\hline%
\instStyle{swv15}&\algoStyle{hcr_65536_nswap}&3740&3818&3826&\textcolor{green}{\textbf{35}}&89s&10'783'296\\%
&\algoStyle{ea_16384_nswap}&\textcolor{green}{\textbf{3577}}&\textcolor{green}{\textbf{3723}}&\textcolor{green}{\textbf{3728}}&50&178s&18'897'833\\%
\hline%
\instStyle{yn4}&\algoStyle{hcr_65536_nswap}&1068&1109&1110&\textcolor{green}{\textbf{12}}&78s&18'756'636\\%
&\algoStyle{ea_16384_nswap}&\textcolor{green}{\textbf{1022}}&\textcolor{green}{\textbf{1063}}&\textcolor{green}{\textbf{1061}}&16&168s&26'699'633\\%
%
\hline%
\end{tabular}%
}%
\end{center}%
}%
}%
%
\locateGraphic{3}{width=0.95\paperwidth}{graphics/hcr_nswap/gantt_hcr_65536_nswap_abz7_732}{0.025}{0.26}%
\locateGraphic{4}{width=0.95\paperwidth}{graphics/ea_nocr_gantt/gantt_ea_nocr_abz7_732}{0.025}{0.26}%
\locateGraphic{5}{width=0.95\paperwidth}{graphics/hcr_nswap/gantt_hcr_65536_nswap_la24_974}{0.025}{0.26}%
\locateGraphic{6}{width=0.95\paperwidth}{graphics/ea_nocr_gantt/gantt_ea_nocr_la24_974}{0.025}{0.26}%
\locateGraphic{7}{width=0.95\paperwidth}{graphics/hcr_nswap/gantt_hcr_65536_nswap_swv15_3826}{0.025}{0.26}%
\locateGraphic{8}{width=0.95\paperwidth}{graphics/ea_nocr_gantt/gantt_ea_nocr_swv15_3826}{0.025}{0.26}%
\locateGraphic{9}{width=0.95\paperwidth}{graphics/hcr_nswap/gantt_hcr_65536_nswap_yn4_1110}{0.025}{0.26}%
\locateGraphic{10}{width=0.95\paperwidth}{graphics/ea_nocr_gantt/gantt_ea_nocr_yn4_1110}{0.025}{0.26}%
\end{frame}%
%
\begin{frame}[t]%
\frametitle{Progress over Time}%
\locateGraphic{2-3}{width=0.9\paperwidth}{graphics/ea_nocr_progress/ea_nocr_progress_abz7_log}{0.05}{0.2}%
\locateGraphic{4}{width=0.9\paperwidth}{graphics/ea_nocr_progress/ea_nocr_progress_la24_log}{0.05}{0.2}%
\locateGraphic{5}{width=0.9\paperwidth}{graphics/ea_nocr_progress/ea_nocr_progress_swv15_log}{0.05}{0.2}%
\locateGraphic{6}{width=0.9\paperwidth}{graphics/ea_nocr_progress/ea_nocr_progress_yn4_log}{0.05}{0.2}%
\locateGraphic{7-8}{width=0.9\paperwidth}{graphics/ea_nocr_progress/ea_nocr_progress_abz7}{0.05}{0.2}%
\locateGraphic{9}{width=0.9\paperwidth}{graphics/ea_nocr_progress/ea_nocr_progress_la24}{0.05}{0.2}%
\locateGraphic{10}{width=0.9\paperwidth}{graphics/ea_nocr_progress/ea_nocr_progress_swv15}{0.05}{0.2}%
\locateGraphic{11}{width=0.9\paperwidth}{graphics/ea_nocr_progress/ea_nocr_progress_yn4}{0.05}{0.2}%
\begin{center}%
What progress does the algorithm make over time?
\par%
\vspace{0.65\paperheight}%
\only<3-6>{On the log-scale, it seems as if the EA first is much slower and very late in the search makes much progress.}%
\only<8->{However, on the linear time scale we can see that it keeps improving slowly but surely during all the time.}%
\end{center}
\end{frame}%
%
\begin{frame}[t]%
\frametitle{Relationship EA / Hill Climber / Random Sampling}%
\begin{itemize}%
\item We can imagine this first version of the $(\mu+\lambda)$~EA as a generalized version of a hill climber.%
\item<2-> Or the other way around: A hill climber is a $(1+1)$~EA%
\uncover<3->{, i.e., an EA where we always remember the $\mu=1$ best solutions%
\uncover<4->{ and use them as parents for $\lambda=1$ new solutions%
\uncover<5->{, which we create using the unary modification operator as modified copy of the $\mu=1$ parent.%
}}}%
\item<6-> On the other hand: For the first $\mu+\lambda$ (random) solutions it generates, the EA always behaves exactly like a random sampling algorithm.%
\only<-7>{\item<7-> If $\mu+\lambda\rightarrow+\infty$, the EA \emph{becomes} a random sampling algorithm.}%
\item<8-> Actually, for $\mu+\lambda\geq \eta$, with an $\eta$~large enough to completely exhaust our computational budget (here: 3~min), the EA \alert{is} a random sampling algorithm.%
\item<9-> \textbf{\alert{We can regard this basic EA as a way to choose an algorithm behavior in between random sampling and hill climbing!}}%
\end{itemize}%
\end{frame}%
%
%
\begin{frame}[t]%
\frametitle{Exploration versus Exploitation}%
\begin{itemize}%
\item \textbf{\alert{We can regard this basic EA as a way to choose an algorithm behavior in between random sampling and hill climbing!}}%
\item<2-> The parameter~$\mu$ basically allows us to ``tune'' between these two behaviors\cite{WWCTL2016GVLSTIOPSOEAP}%
\item<3-> If we pick it small, our algorithm becomes more ``greedy''.%
\item<4-> It will investigate (\alert{exploit}) the neighborhood current best solutions more eagerly\only<5->{, which means that it will trace down local optima faster\only<6->{ but be trapped more easily in local optima as well}}.%
\item<7-> The bigger~$\mu$, the more points in the search space are maintained and the more likely are we do to good ``global'' search, we do \alert{more exploration}. \uncover<8->{%
We pay for that by a slower exploitation (investigation) of the current best solution (because we always work on all $\mu$~points, not just one).}%
\item<9-> This is dilemma of \alert{Exploration versus Exploitation}.\cite{ES1998EA,WCT2012EOPABT,WZCN2009WIOD,WGOEB}%
\end{itemize}%
\end{frame}%
%
\section{Algorithm Concept: Binary Operator}%
%
\begin{frame}%
\frametitle{Binary Search Operator}%
\begin{itemize}%
\item We now have more than one candidate solution in our ``population.''%
\item<2-> But we only use one existing point from~$\searchSpace$ as ``blueprint'' when we create a new one.%
\item<3-> Why can't we use \emph{two} instead?\uncover<4->{%
\begin{itemize}%
\item If two candidate solutions have been selected, they are probably good.%
\item<5-> If two different candidate solutions are good, they may have different positive characteristics.%
\item<6-> Let's try to create a new ``offspring'' solution which inherits characteristics from both ``parents''.%
\item<7-> It could maybe inherit the positive traits and combine them\dots%
\end{itemize}%
}%
\item<8-> This is the idea of the \alert{crossover} or \alert{recombination} operator in Evolutionary Algorithms.\cite{G1989GA,H1975GA,WGOEB}%
\end{itemize}%
\end{frame}%
%
\begin{frame}%
\frametitle{\texorpdfstring{$(\mu+\lambda)$}{(mu+lambda)}~EA with Recombination}%
\begin{itemize}%
\item The $(\mu+\lambda)$~EAs with recombination work as follows:\uncover<2->{%
\begin{enumerate}%
\item Generate a population of $\mu+\lambda$~random points in the search space (and map them to solutions and evaluate them).%
\item<3-> From the complete population, select the $\mu$~best points as ``parents'' for the next ``generation,'' discard the remaining $\lambda$~points.%
\item<4-> Generate $\lambda$~new ``offspring'' points\uncover<5->{ by\uncover<7->{ either}%
\begin{enumerate}%
\item applying a binary recombination operator which combines two existing parents to one new offspring\uncover<6->{ with probability $cr$\uncover<7->{ \alert<7>{or}%
\item<7-> applying a unary search operator which creates a randomly modified copy from a parent as offspring.%
}}
\end{enumerate}%
\item<8-> Evaluate the~$\lambda$ offsprings, add them to the population, and go back to step~\enumerateItem{2}%
}%
\end{enumerate}%
}%
\end{itemize}%
\end{frame}%
%
\begin{frame}%
\frametitle{Implementation}%
\only<1>{\listing{0.9}{1.7}{language=myJava,mathescape=false}{code/EANoCR.java}}%
\only<2>{\listing{0.9}{1.7}{language=myJava,mathescape=false}{code/EAWithCR_1.java}}%
\only<3>{\listing{0.9}{1.7}{language=myJava,mathescape=false}{code/EAWithCR_2.java}}%
\only<4>{\listing{0.9}{1.7}{language=myJava,mathescape=false}{code/EAWithCR_3.java}}%
\only<5>{\listing{0.9}{1.7}{language=myJava,mathescape=false}{code/EAWithCR_4.java}}%
\only<6>{\listing{0.9}{1.7}{language=myJava,mathescape=false}{code/EAWithCR.java}}%
\end{frame}%
%
\endPresentation%
\end{document}%%
\endinput%
%
